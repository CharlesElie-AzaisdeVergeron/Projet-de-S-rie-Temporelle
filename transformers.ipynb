{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33fdd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source - https://stackoverflow.com/a\n",
    "# Posted by FYH\n",
    "# Retrieved 2026-01-22, License - CC BY-SA 4.0\n",
    "\n",
    "import numpy as np\n",
    "def dummy_npwarn_decorator_factory():\n",
    "  def npwarn_decorator(x):\n",
    "    return x\n",
    "  return npwarn_decorator\n",
    "np._no_nep50_warning = getattr(np, '_no_nep50_warning', dummy_npwarn_decorator_factory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fd0b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogluon.tabular in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (2.3.1)\n",
      "Requirement already satisfied: scipy<1.17,>=1.5.4 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (1.16.1)\n",
      "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (1.7.1)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (3.5)\n",
      "Requirement already satisfied: autogluon.core==1.5.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (1.5.0)\n",
      "Requirement already satisfied: autogluon.features==1.5.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (1.5.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (4.67.1)\n",
      "Requirement already satisfied: requests in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (2.32.4)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (3.10.3)\n",
      "Requirement already satisfied: boto3<2,>=1.10 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (1.42.32)\n",
      "Requirement already satisfied: autogluon.common==1.5.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (1.5.0)\n",
      "Requirement already satisfied: pyarrow<21.0.0,>=7.0.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.tabular) (20.0.0)\n",
      "Requirement already satisfied: psutil<7.2.0,>=5.7.3 in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.tabular) (7.0.0)\n",
      "Requirement already satisfied: joblib<1.7,>=1.2 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.tabular) (1.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.tabular) (6.0.2)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.32 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (1.42.32)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from botocore<1.43.0,>=1.42.32->boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from botocore<1.43.0,>=1.42.32->boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (2.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.32->boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.tabular) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from tqdm<5,>=4.38->autogluon.core==1.5.0->autogluon.tabular) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->autogluon.core==1.5.0->autogluon.tabular) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->autogluon.core==1.5.0->autogluon.tabular) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->autogluon.core==1.5.0->autogluon.tabular) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install autogluon.tabular\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd04e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_registered/\"\n",
      "Preset alias specified: 'best' maps to 'best_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.13.5\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          16\n",
      "Pytorch Version:    2.9.1+cpu\n",
      "CUDA Version:       CUDA is not available\n",
      "Memory Avail:       17.09 GB / 31.93 GB (53.5%)\n",
      "Disk Space Avail:   112.83 GB / 930.30 GB (12.1%)\n",
      "===================================================\n",
      "Presets specified: ['best']\n",
      "Loaded data from: train.csv | Columns = 17 / 17 | Rows = 13903 -> 13903\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1493: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ImportError('ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.43.0,<2.53.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"c:\\Users\\charl\\Desktop\\code\\ag_registered\\ds_sub_fit\\sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 150s\n",
      "AutoGluon will save models to \"c:\\Users\\charl\\Desktop\\code\\ag_registered\\ds_sub_fit\\sub_fit_ho\"\n",
      "Train Data Rows:    12358\n",
      "Train Data Columns: 16\n",
      "Label Column:       registered\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17493.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                        : 11 | ['instant', 'season', 'yr', 'mnth', 'hr', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['dteday']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                  : 8 | ['instant', 'season', 'mnth', 'hr', 'weekday', ...]\n",
      "\t\t('int', ['bool'])            : 3 | ['yr', 'holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 4 | ['dteday', 'dteday.year', 'dteday.day', 'dteday.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.54 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 99.93s of the 149.92s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.43.0,<2.53.0\"`\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 97.68s of the 147.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 97.50s of the 147.49s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/17.0 GB\n",
      "\t-3.1156\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.06s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 94.88s of the 144.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 94.69s of the 144.68s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/16.8 GB\n",
      "\t-4.4316\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 92.93s of the 142.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 92.73s of the 142.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 92.51s of the 142.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 35)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 42)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 51)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 57)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 55)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 74)\n",
      "\t-8.213\t = Validation score   (-root_mean_squared_error)\n",
      "\t88.37s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4.00s of the 53.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 3.76s of the 53.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 3.55s of the 53.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tNot enough time to train first epoch. Stopped on Update 84 (Epoch 0))\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2.58s of the 52.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2.34s of the 52.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r191_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2.13s of the 52.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r9_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1.92s of the 51.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r96_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1.70s of the 51.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tNot enough time to train first epoch. (Time Required: 0.33s, Time Left: 0.12s)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r22_BAG_L1.\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1.38s of the 51.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_r33_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1.14s of the 51.14s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/17.3 GB\n",
      "\t-5.4744\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 149.93s of the 49.47s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/17.1 GB\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.909, 'NeuralNetTorch_BAG_L1': 0.091}\n",
      "\t-3.0156\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 49.44s of the 49.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 49.22s of the 49.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 49.00s of the 48.98s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/17.1 GB\n",
      "\t-3.017\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.62s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 45.84s of the 45.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 45.63s of the 45.61s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/17.1 GB\n",
      "\t-2.9132\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 44.11s of the 44.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 43.89s of the 43.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 43.68s of the 43.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 19)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 20)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 21)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 22)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 23)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 25)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 28)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 34)\n",
      "\t-7.4758\t = Validation score   (-root_mean_squared_error)\n",
      "\t41.59s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1.92s of the 1.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 1.68s of the 1.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 149.93s of the 1.17s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/17.4 GB\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.556, 'RandomForestMSE_BAG_L1': 0.278, 'RandomForestMSE_BAG_L2': 0.111, 'NeuralNetTorch_BAG_L1': 0.056}\n",
      "\t-2.8414\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 148.87s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 4770.8 rows/s (1545 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\charl\\Desktop\\code\\ag_registered\\ds_sub_fit\\sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                    model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3      -2.341592  -2.841420  root_mean_squared_error        1.607364       1.962965   95.949637                 0.010471                0.000287           0.013093            3       True          9\n",
      "1    ExtraTreesMSE_BAG_L2      -2.432932  -2.913168  root_mean_squared_error        1.437518       1.621050   93.319166                 0.187724                0.334714           0.960994            2       True          7\n",
      "2     WeightedEnsemble_L2      -2.484626  -3.015612  root_mean_squared_error        0.558473       0.444911   90.440156                 0.012369                0.000454           0.011955            2       True          5\n",
      "3  RandomForestMSE_BAG_L2      -2.751814  -3.016954  root_mean_squared_error        1.409169       1.627964   94.975550                 0.159375                0.341629           2.617378            2       True          6\n",
      "4  RandomForestMSE_BAG_L1      -2.753934  -3.115633  root_mean_squared_error        0.315444       0.354813    2.055914                 0.315444                0.354813           2.055914            1       True          1\n",
      "5    ExtraTreesMSE_BAG_L1      -4.269966  -4.431648  root_mean_squared_error        0.317806       0.423793    1.080114                 0.317806                0.423793           1.080114            1       True          2\n",
      "6   ExtraTrees_r42_BAG_L1      -5.114523  -5.474404  root_mean_squared_error        0.385884       0.418085    0.849857                 0.385884                0.418085           0.849857            1       True          4\n",
      "7   NeuralNetTorch_BAG_L2      -6.650767  -7.475836  root_mean_squared_error        1.497445       1.395350  133.946557                 0.247651                0.109015          41.588384            2       True          8\n",
      "8   NeuralNetTorch_BAG_L1      -7.746248  -8.213042  root_mean_squared_error        0.230660       0.089644   88.372287                 0.230660                0.089644          88.372287            1       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t151s\t = DyStack   runtime |\t449s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 449s\n",
      "AutoGluon will save models to \"c:\\Users\\charl\\Desktop\\code\\ag_registered\"\n",
      "Train Data Rows:    13903\n",
      "Train Data Columns: 16\n",
      "Label Column:       registered\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17836.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.37 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                        : 11 | ['instant', 'season', 'yr', 'mnth', 'hr', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['dteday']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                  : 8 | ['instant', 'season', 'mnth', 'hr', 'weekday', ...]\n",
      "\t\t('int', ['bool'])            : 3 | ['yr', 'holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 4 | ['dteday', 'dteday.year', 'dteday.day', 'dteday.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.74 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 299.09s of the 448.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 298.88s of the 448.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 298.67s of the 448.32s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/17.4 GB\n",
      "\t-2.7912\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.24s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 295.83s of the 445.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 295.63s of the 445.28s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/17.3 GB\n",
      "\t-4.0274\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 293.91s of the 443.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 293.64s of the 443.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 293.38s of the 443.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t-8.2309\t = Validation score   (-root_mean_squared_error)\n",
      "\t106.76s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 186.48s of the 336.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 186.26s of the 335.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 186.05s of the 335.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 64)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 67)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 69)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 71)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 76)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 80)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 88)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t-5.7259\t = Validation score   (-root_mean_squared_error)\n",
      "\t174.28s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 11.62s of the 161.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 11.37s of the 161.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r191_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 11.16s of the 160.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r9_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 10.95s of the 160.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r96_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 10.74s of the 160.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 4)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 5)\n",
      "\t-13.1438\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.95s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 0.62s of the 150.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_r33_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 0.37s of the 150.02s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/17.4 GB\n",
      "\t-4.9853\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 148.25s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/17.1 GB\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.8, 'NeuralNetTorch_r79_BAG_L1': 0.12, 'ExtraTreesMSE_BAG_L1': 0.04, 'NeuralNetTorch_BAG_L1': 0.04}\n",
      "\t-2.6489\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 148.22s of the 148.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 148.01s of the 147.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 147.79s of the 147.77s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/17.1 GB\n",
      "\t-2.6025\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.58s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 143.76s of the 143.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 143.54s of the 143.52s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/16.9 GB\n",
      "\t-2.4686\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 141.91s of the 141.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 141.69s of the 141.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 141.46s of the 141.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t-7.6835\t = Validation score   (-root_mean_squared_error)\n",
      "\t88.29s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 52.98s of the 52.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 52.74s of the 52.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 52.52s of the 52.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 19)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 21)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 25)\n",
      "\t-8.3621\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.81s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 2.24s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/17.3 GB\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.706, 'RandomForestMSE_BAG_L1': 0.235, 'NeuralNetTorch_r79_BAG_L1': 0.059}\n",
      "\t-2.4257\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 446.62s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 3710.9 rows/s (1738 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\charl\\Desktop\\code\\ag_registered\")\n",
      "Loaded data from: test.csv | Columns = 17 / 17 | Rows = 3476 -> 3476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3990"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train a predictor for \"registered\"\n",
    "predictor_registered = TabularPredictor(label=\"registered\", path=\"ag_registered/\").fit(\"train.csv\", presets=\"best\",time_limit=600)\n",
    "predictions_registered = predictor_registered.predict(\"test.csv\")\n",
    "\n",
    "# Explicitly delete and collect garbage to release file handles\n",
    "del predictor_registered\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb143448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_casual/\"\n",
      "Preset alias specified: 'best' maps to 'best_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.13.5\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          16\n",
      "Pytorch Version:    2.9.1+cpu\n",
      "CUDA Version:       CUDA is not available\n",
      "Memory Avail:       17.26 GB / 31.93 GB (54.1%)\n",
      "Disk Space Avail:   112.82 GB / 930.30 GB (12.1%)\n",
      "===================================================\n",
      "Presets specified: ['best']\n",
      "Loaded data from: train.csv | Columns = 17 / 17 | Rows = 13903 -> 13903\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1493: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ImportError('ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.43.0,<2.53.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"c:\\Users\\charl\\Desktop\\code\\ag_casual\\ds_sub_fit\\sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 150s\n",
      "AutoGluon will save models to \"c:\\Users\\charl\\Desktop\\code\\ag_casual\\ds_sub_fit\\sub_fit_ho\"\n",
      "Train Data Rows:    12363\n",
      "Train Data Columns: 16\n",
      "Label Column:       casual\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 5 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 5 examples. AutoGluon will only keep 188 out of 303 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 5 examples that will be kept for training models: 0.9794548248806924\n",
      "Train Data Class Count: 188\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17670.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.07 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                        : 11 | ['instant', 'season', 'yr', 'mnth', 'hr', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['dteday']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                  : 8 | ['instant', 'season', 'mnth', 'hr', 'weekday', ...]\n",
      "\t\t('int', ['bool'])            : 3 | ['yr', 'holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 4 | ['dteday', 'dteday.year', 'dteday.day', 'dteday.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.51 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 99.92s of the 149.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 99.71s of the 149.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 99.50s of the 149.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 99.29s of the 149.28s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.267 GB available memory (61.394%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.28 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestGini_BAG_L1... Skipping this model.\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 99.09s of the 149.08s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.267 GB available memory (61.392%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.28 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestEntr_BAG_L1... Skipping this model.\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 98.88s of the 148.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 98.65s of the 148.64s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.252 GB available memory (61.448%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.28 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesGini_BAG_L1... Skipping this model.\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 98.42s of the 148.40s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.222 GB available memory (61.553%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.28 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesEntr_BAG_L1... Skipping this model.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 98.20s of the 148.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 97.98s of the 147.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 44)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 45)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 47)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 49)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 51)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 55)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 60)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 73)\n",
      "\t0.2246\t = Validation score   (accuracy)\n",
      "\t93.69s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4.05s of the 54.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 3.81s of the 53.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 3.60s of the 53.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tNot enough time to train first epoch. (Time Required: 0.32s, Time Left: 0.31s)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 3.29s of the 53.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 3.06s of the 53.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r191_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2.82s of the 52.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r9_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 2.58s of the 52.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r96_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 2.35s of the 52.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tNot enough time to train first epoch. (Time Required: 0.35s, Time Left: 0.18s)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r22_BAG_L1.\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 2.02s of the 52.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_r33_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1.80s of the 51.79s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.145 GB available memory (61.830%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.29 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTrees_r42_BAG_L1... Skipping this model.\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 1.61s of the 51.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r137_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1.39s of the 51.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r102_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 1.15s of the 51.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r13_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 0.94s of the 50.93s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.143 GB available memory (61.838%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.29 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForest_r195_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 0.74s of the 50.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r188_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 0.53s of the 50.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r145_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 0.30s of the 50.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_r89_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 0.08s of the 50.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r30_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 149.91s of the 49.66s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/17.1 GB\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.2246\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 49.57s of the 49.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 49.19s of the 49.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 48.83s of the 48.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 48.45s of the 48.42s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.137 GB available memory (61.859%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.29 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestGini_BAG_L2... Skipping this model.\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 48.15s of the 48.12s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.145 GB available memory (61.830%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.29 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestEntr_BAG_L2... Skipping this model.\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 47.85s of the 47.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 47.47s of the 47.44s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.144 GB available memory (61.832%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.29 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesGini_BAG_L2... Skipping this model.\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 47.17s of the 47.14s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 10.601 GB out of 17.152 GB available memory (61.803%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.29 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesEntr_BAG_L2... Skipping this model.\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 46.88s of the 46.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 46.39s of the 46.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 20)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 22)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 27)\n",
      "\t0.2106\t = Validation score   (accuracy)\n",
      "\t43.31s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1.86s of the 1.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 149.91s of the 1.24s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.1/17.0 GB\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.706, 'NeuralNetTorch_BAG_L2': 0.294}\n",
      "\t0.2293\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 149.69s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1471.6 rows/s (1514 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\charl\\Desktop\\code\\ag_casual\\ds_sub_fit\\sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    WeightedEnsemble_L3       0.250649   0.229334    accuracy        1.424213       1.035977  137.849638                 0.016852                0.008193           0.841720            3       True          4\n",
      "1  NeuralNetTorch_BAG_L1       0.238961   0.224626    accuracy        0.221651       0.095909   93.693611                 0.221651                0.095909          93.693611            1       True          1\n",
      "2    WeightedEnsemble_L2       0.238961   0.224626    accuracy        0.235253       0.105278   93.723883                 0.013602                0.009368           0.030272            2       True          2\n",
      "3  NeuralNetTorch_BAG_L2       0.232468   0.210587    accuracy        1.407362       1.027784  137.007918                 1.185710                0.931875          43.314307            2       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t152s\t = DyStack   runtime |\t448s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 448s\n",
      "AutoGluon will save models to \"c:\\Users\\charl\\Desktop\\code\\ag_casual\"\n",
      "Train Data Rows:    13903\n",
      "Train Data Columns: 16\n",
      "Label Column:       casual\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 6 examples. AutoGluon will only keep 188 out of 303 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 6 examples that will be kept for training models: 0.9809393656045458\n",
      "Train Data Class Count: 188\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17451.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.33 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                        : 11 | ['instant', 'season', 'yr', 'mnth', 'hr', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['dteday']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                  : 8 | ['instant', 'season', 'mnth', 'hr', 'weekday', ...]\n",
      "\t\t('int', ['bool'])            : 3 | ['yr', 'holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 4 | ['dteday', 'dteday.year', 'dteday.day', 'dteday.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.70 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 298.82s of the 448.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 298.60s of the 448.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 298.38s of the 447.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 298.12s of the 447.63s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 11.939 GB out of 17.059 GB available memory (69.987%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.45 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestGini_BAG_L1... Skipping this model.\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 297.92s of the 447.43s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 11.939 GB out of 17.052 GB available memory (70.018%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.45 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestEntr_BAG_L1... Skipping this model.\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 297.69s of the 447.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 297.47s of the 446.98s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 11.939 GB out of 17.051 GB available memory (70.020%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.45 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesGini_BAG_L1... Skipping this model.\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 297.27s of the 446.78s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 11.939 GB out of 17.053 GB available memory (70.011%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.45 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesEntr_BAG_L1... Skipping this model.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 297.07s of the 446.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 296.86s of the 446.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 117)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 120)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 125)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 127)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 135)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 143)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 159)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 192)\n",
      "\t0.3987\t = Validation score   (accuracy)\n",
      "\t284.51s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 12.09s of the 161.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 11.86s of the 161.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 11.64s of the 161.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 4)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 4)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 4)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "\t0.1615\t = Validation score   (accuracy)\n",
      "\t10.61s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 0.77s of the 150.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 0.53s of the 150.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r191_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 0.32s of the 149.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r9_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 0.10s of the 149.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r96_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 149.22s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.1/16.1 GB\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.3987\t = Validation score   (accuracy)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 148.03s of the 147.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 147.45s of the 147.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 146.94s of the 146.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 146.40s of the 146.34s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 11.939 GB out of 16.202 GB available memory (73.689%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.52 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestGini_BAG_L2... Skipping this model.\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 145.96s of the 145.89s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 11.939 GB out of 16.272 GB available memory (73.374%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.52 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestEntr_BAG_L2... Skipping this model.\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 145.52s of the 145.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 144.97s of the 144.90s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 11.939 GB out of 16.270 GB available memory (73.381%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.52 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesGini_BAG_L2... Skipping this model.\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 144.58s of the 144.51s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 11.939 GB out of 16.292 GB available memory (73.283%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.52 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesEntr_BAG_L2... Skipping this model.\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 144.20s of the 144.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 143.55s of the 143.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 50)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 54)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 54)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 58)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 61)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 63)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 71)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 84)\n",
      "\t0.4221\t = Validation score   (accuracy)\n",
      "\t135.82s\t = Training   runtime\n",
      "\t1.58s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 5.81s of the 5.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 12.443 GB out of 16.146 GB available memory (77.068%)... (90.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.08 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 5.29s of the 5.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 4.82s of the 4.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 2.51s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.1/16.2 GB\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.619, 'NeuralNetTorch_BAG_L2': 0.381}\n",
      "\t0.43\t = Validation score   (accuracy)\n",
      "\t1.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 447.5s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 957.6 rows/s (1705 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\charl\\Desktop\\code\\ag_casual\")\n",
      "Loaded data from: test.csv | Columns = 17 / 17 | Rows = 3476 -> 3476\n"
     ]
    }
   ],
   "source": [
    "# Train a predictor for \"casual\"\n",
    "predictor_casual = TabularPredictor(label=\"casual\", path=\"ag_casual/\").fit(\"train.csv\", presets=\"best\",time_limit=600)\n",
    "predictions_casual = predictor_casual.predict(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52366133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 registered: 0.998\n",
      "MAE registered: 2.66\n",
      "RMSE registered: 8.32\n",
      "R2 casual: 0.963\n",
      "MAE casual: 4.36\n",
      "RMSE casual: 10.72\n",
      "R2 cnt: 0.996\n",
      "MAE cnt: 5.28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'R2 registered: 0.999\\nMAE registered: 1.89\\nRMSE registered: 6.52\\nR2 casual: 0.980\\nMAE casual: 3.03\\nRMSE casual: 7.87\\nR2 cnt: 0.998\\nMAE cnt: 3.79'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les vraies valeurs du fichier test\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "y_true_registered = test_df[\"registered\"].values\n",
    "y_true_casual = test_df[\"casual\"].values\n",
    "\n",
    "if 'registered' in test_df.columns and 'casual' in test_df.columns:\n",
    "    # R2 et MAE pour registered\n",
    "    r2_registered = r2_score(y_true_registered, predictions_registered)\n",
    "    mae_registered = mean_absolute_error(y_true_registered, predictions_registered)\n",
    "    rmse_registered = np.sqrt(mean_squared_error(y_true_registered, predictions_registered))\n",
    "\n",
    "    print(f\"R2 registered: {r2_registered:.3f}\")\n",
    "    print(f\"MAE registered: {mae_registered:.2f}\")\n",
    "    print(f\"RMSE registered: {rmse_registered:.2f}\")\n",
    "\n",
    "    # R2 et MAE pour casual\n",
    "    rmse_casual = np.sqrt(mean_squared_error(y_true_casual, predictions_casual))\n",
    "    r2_casual = r2_score(y_true_casual, predictions_casual)\n",
    "    mae_casual = mean_absolute_error(y_true_casual, predictions_casual)\n",
    "    print(f\"R2 casual: {r2_casual:.3f}\")\n",
    "    print(f\"MAE casual: {mae_casual:.2f}\")\n",
    "    print(f\"RMSE casual: {rmse_casual:.2f}\")\n",
    "\n",
    "    # R2 et MAE pour cnt (registered + casual)\n",
    "    cnt_true = y_true_registered + y_true_casual\n",
    "    cnt_pred = predictions_registered + predictions_casual\n",
    "    r2_cnt = r2_score(cnt_true, cnt_pred)\n",
    "    mae_cnt = mean_absolute_error(cnt_true, cnt_pred)\n",
    "    print(f\"R2 cnt: {r2_cnt:.3f}\")\n",
    "    print(f\"MAE cnt: {mae_cnt:.2f}\")\n",
    "else:\n",
    "    print(\"Les colonnes 'registered' et 'casual' ne sont pas prsentes dans test.csv.\")\n",
    "\n",
    "\"\"\"R2 registered: 0.999\n",
    "MAE registered: 1.89\n",
    "RMSE registered: 6.52\n",
    "R2 casual: 0.980\n",
    "MAE casual: 3.03\n",
    "RMSE casual: 7.87\n",
    "R2 cnt: 0.998\n",
    "MAE cnt: 3.79\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b5f57",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Registered\u001b[39;00m\n\u001b[32m     10\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m plt.plot(\u001b[43my_true_registered\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m[idx], label=\u001b[33m\"\u001b[39m\u001b[33mVrai registered\u001b[39m\u001b[33m\"\u001b[39m, marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m plt.plot(predictions_registered.values[idx], label=\u001b[33m\"\u001b[39m\u001b[33mPrdit registered\u001b[39m\u001b[33m\"\u001b[39m, marker=\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33morange\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mRegistered sur une semaine\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Slectionner les 7 premiers jours (ou 7 premires lignes)\n",
    "n_days = 30\n",
    "idx = slice(0, n_days)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Registered\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(y_true_registered[idx], label=\"Vrai registered\", marker='o', color='blue')\n",
    "plt.plot(predictions_registered.values[idx], label=\"Prdit registered\", marker='x', color='orange')\n",
    "plt.title(\"Registered sur une semaine\")\n",
    "plt.xlabel(\"Jour\")\n",
    "plt.ylabel(\"Valeur\")\n",
    "plt.legend()\n",
    "\n",
    "# Casual\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(y_true_casual[idx], label=\"Vrai casual\", marker='o', color='green')\n",
    "plt.plot(predictions_casual.values[idx], label=\"Prdit casual\", marker='x', color='red')\n",
    "plt.title(\"Casual sur une semaine\")\n",
    "plt.xlabel(\"Jour\")\n",
    "plt.ylabel(\"Valeur\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fab89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nombre de jours  afficher\n",
    "n_days = 30\n",
    "idx = slice(0, n_days)\n",
    "\n",
    "# Calcul des sries cnt (total)\n",
    "cnt_true = y_true_registered.values[idx] + y_true_casual.values[idx]\n",
    "cnt_pred = predictions_registered.values[idx] + predictions_casual.values[idx]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(cnt_true, label=\"Vrai cnt\", marker='o', color='blue')\n",
    "plt.plot(cnt_pred, label=\"Prdit cnt\", marker='x', color='orange')\n",
    "plt.title(\"Comparaison cnt (registered + casual) sur une semaine\")\n",
    "plt.xlabel(\"Jour\")\n",
    "plt.ylabel(\"Total cnt\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Charger les donnes\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Paramtre : intervalle de rentrainement\n",
    "k = 5  # Rentraner tous les 5 nouveaux points\n",
    "n = len(test_df)\n",
    "\n",
    "# Listes pour stocker les prdictions\n",
    "preds_registered = []\n",
    "preds_casual = []\n",
    "\n",
    "for i in range(n):\n",
    "    # Rentraner tous les k points ou  la premire itration\n",
    "    if i % k == 0 or i == 0:\n",
    "        predictor_registered = TabularPredictor(label=\"registered\", path=\"ag_registered/\").fit(train_df, presets=\"best\")\n",
    "        predictor_casual = TabularPredictor(label=\"casual\", path=\"ag_casual/\").fit(train_df, presets=\"best\")\n",
    "    \n",
    "    # Prdire la nouvelle donne\n",
    "    X_new = test_df.iloc[[i]].copy()\n",
    "    pred_reg = predictor_registered.predict(X_new).values[0]\n",
    "    pred_cas = predictor_casual.predict(X_new).values[0]\n",
    "    preds_registered.append(pred_reg)\n",
    "    preds_casual.append(pred_cas)\n",
    "    \n",
    "    # Ajouter la vraie nouvelle donne au train pour la prochaine itration\n",
    "    train_df = pd.concat([train_df, test_df.iloc[[i]]], ignore_index=True)\n",
    "    \n",
    "    # Librer la mmoire\n",
    "    del predictor_registered, predictor_casual\n",
    "    gc.collect()\n",
    "\n",
    "# Rsultats sous forme de sries pandas\n",
    "preds_registered = pd.Series(preds_registered, name=\"registered_pred\")\n",
    "preds_casual = pd.Series(preds_casual, name=\"casual_pred\")\n",
    "\n",
    "\n",
    "n_points = 30  # Nombre de points  afficher (adapte selon la taille de test_df)\n",
    "idx = slice(0, n_points)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Registered\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(test_df['registered'].values[idx], label=\"Vrai registered\", marker='o', color='blue')\n",
    "plt.plot(preds_registered.values[idx], label=\"Prdit registered (squentiel)\", marker='x', color='orange')\n",
    "plt.title(\"volution des prdictions registered (squentiel)\")\n",
    "plt.ylabel(\"Registered\")\n",
    "plt.legend()\n",
    "\n",
    "# Casual\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(test_df['casual'].values[idx], label=\"Vrai casual\", marker='o', color='green')\n",
    "plt.plot(preds_casual.values[idx], label=\"Prdit casual (squentiel)\", marker='x', color='red')\n",
    "plt.title(\"volution des prdictions casual (squentiel)\")\n",
    "plt.ylabel(\"Casual\")\n",
    "plt.legend()\n",
    "\n",
    "# Total cnt\n",
    "plt.subplot(3, 1, 3)\n",
    "cnt_true = test_df['registered'].values[idx] + test_df['casual'].values[idx]\n",
    "cnt_pred = preds_registered.values[idx] + preds_casual.values[idx]\n",
    "plt.plot(cnt_true, label=\"Vrai cnt\", marker='o', color='purple')\n",
    "plt.plot(cnt_pred, label=\"Prdit cnt (squentiel)\", marker='x', color='brown')\n",
    "plt.title(\"volution des prdictions cnt (squentiel)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Total cnt\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
