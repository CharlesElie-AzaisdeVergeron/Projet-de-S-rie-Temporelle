{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33fdd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source - https://stackoverflow.com/a\n",
    "# Posted by FYH\n",
    "# Retrieved 2026-01-22, License - CC BY-SA 4.0\n",
    "\n",
    "import numpy as np\n",
    "def dummy_npwarn_decorator_factory():\n",
    "  def npwarn_decorator(x):\n",
    "    return x\n",
    "  return npwarn_decorator\n",
    "np._no_nep50_warning = getattr(np, '_no_nep50_warning', dummy_npwarn_decorator_factory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd04e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogluon.tabular in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (2.3.1)\n",
      "Requirement already satisfied: scipy<1.17,>=1.5.4 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (1.16.1)\n",
      "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (1.7.1)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (3.5)\n",
      "Requirement already satisfied: autogluon.core==1.5.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (1.5.0)\n",
      "Requirement already satisfied: autogluon.features==1.5.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.tabular) (1.5.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (4.67.1)\n",
      "Requirement already satisfied: requests in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (2.32.4)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (3.10.3)\n",
      "Requirement already satisfied: boto3<2,>=1.10 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (1.42.32)\n",
      "Requirement already satisfied: autogluon.common==1.5.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.core==1.5.0->autogluon.tabular) (1.5.0)\n",
      "Requirement already satisfied: pyarrow<21.0.0,>=7.0.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.tabular) (20.0.0)\n",
      "Requirement already satisfied: psutil<7.2.0,>=5.7.3 in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.tabular) (7.0.0)\n",
      "Requirement already satisfied: joblib<1.7,>=1.2 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.tabular) (1.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.tabular) (6.0.2)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.32 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (1.42.32)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from botocore<1.43.0,>=1.42.32->boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from botocore<1.43.0,>=1.42.32->boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (2.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.tabular) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.32->boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.tabular) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.tabular) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\charl\\appdata\\roaming\\python\\python313\\site-packages (from tqdm<5,>=4.38->autogluon.core==1.5.0->autogluon.tabular) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->autogluon.core==1.5.0->autogluon.tabular) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->autogluon.core==1.5.0->autogluon.tabular) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\charl\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->autogluon.core==1.5.0->autogluon.tabular) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_registered/\"\n",
      "Preset alias specified: 'best' maps to 'best_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.13.5\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          16\n",
      "Pytorch Version:    2.9.1+cpu\n",
      "CUDA Version:       CUDA is not available\n",
      "Memory Avail:       20.67 GB / 31.93 GB (64.8%)\n",
      "Disk Space Avail:   115.44 GB / 930.30 GB (12.4%)\n",
      "===================================================\n",
      "Presets specified: ['best']\n",
      "Loaded data from: train.csv | Columns = 17 / 17 | Rows = 13903 -> 13903\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1493: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ImportError('ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.43.0,<2.53.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"c:\\Users\\charl\\Desktop\\code\\ag_registered\\ds_sub_fit\\sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"c:\\Users\\charl\\Desktop\\code\\ag_registered\\ds_sub_fit\\sub_fit_ho\"\n",
      "Train Data Rows:    12358\n",
      "Train Data Columns: 16\n",
      "Label Column:       registered\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21150.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                        : 11 | ['instant', 'season', 'yr', 'mnth', 'hr', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['dteday']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 4 | ['temp', 'atemp', 'hum', 'windspeed']\n",
      "\t\t('int', [])                  : 8 | ['instant', 'season', 'mnth', 'hr', 'weekday', ...]\n",
      "\t\t('int', ['bool'])            : 3 | ['yr', 'holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 4 | ['dteday', 'dteday.year', 'dteday.day', 'dteday.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.54 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.80s of the 899.92s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.43.0,<2.53.0\"`\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 598.30s of the 898.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 598.17s of the 898.28s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/20.6 GB\n",
      "\t-3.1156\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.26s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 595.35s of the 895.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 595.22s of the 895.34s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/20.2 GB\n",
      "\t-4.4316\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 593.55s of the 893.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 593.41s of the 893.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 593.26s of the 893.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t-8.213\t = Validation score   (-root_mean_squared_error)\n",
      "\t113.72s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 479.38s of the 779.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 479.20s of the 779.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 479.04s of the 779.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 181)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 174)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 222)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t-5.1498\t = Validation score   (-root_mean_squared_error)\n",
      "\t385.09s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 93.78s of the 393.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 93.61s of the 393.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r191_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 93.44s of the 393.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r9_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 93.28s of the 393.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r96_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 93.13s of the 393.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 27)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 28)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 29)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 33)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 34)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 37)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 44)\n",
      "\t-5.1146\t = Validation score   (-root_mean_squared_error)\n",
      "\t88.82s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 4.14s of the 304.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_r33_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 3.95s of the 304.07s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/19.3 GB\n",
      "\t-5.4744\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 2.36s of the 302.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r137_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 2.20s of the 302.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r102_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 2.04s of the 302.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r13_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 1.89s of the 302.00s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/19.0 GB\n",
      "\t-3.7313\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.62s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 299.58s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/18.8 GB\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.643, 'NeuralNetTorch_r22_BAG_L1': 0.214, 'NeuralNetTorch_r79_BAG_L1': 0.143}\n",
      "\t-2.5751\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 299.51s of the 299.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 299.35s of the 299.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 299.20s of the 299.18s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/18.9 GB\n",
      "\t-2.6841\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.29s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 295.47s of the 295.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 295.29s of the 295.27s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/18.8 GB\n",
      "\t-2.5345\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 293.71s of the 293.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.5.0`. \n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 293.54s of the 293.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 293.37s of the 293.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t-6.9013\t = Validation score   (-root_mean_squared_error)\n",
      "\t86.65s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 206.52s of the 206.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 206.36s of the 206.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.5.0`.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 206.21s of the 206.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 76)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 69)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 73)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 84)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 85)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 96)\n",
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 129)\n",
      "\t-5.5432\t = Validation score   (-root_mean_squared_error)\n",
      "\t196.88s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 9.12s of the 9.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=8, gpus=0)\n",
      "\tWarning: Exception caused LightGBM_r131_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.5.0`.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 8.82s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/18.9 GB\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.6, 'RandomForestMSE_BAG_L1': 0.12, 'NeuralNetTorch_r22_BAG_L1': 0.12, 'NeuralNetTorch_r79_BAG_L1': 0.08, 'RandomForestMSE_BAG_L2': 0.08}\n",
      "\t-2.4326\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 891.22s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2608.4 rows/s (1545 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\charl\\Desktop\\code\\ag_registered\\ds_sub_fit\\sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'c:\\\\Users\\\\charl\\\\Desktop\\\\code\\\\ag_registered\\\\ds_sub_fit\\\\sub_fit_ho\\\\models\\\\LightGBMLarge_BAG_L1\\\\S1F3\\\\model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogluon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtabular\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TabularPredictor\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Train a predictor for \"registered\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m predictor_registered = \u001b[43mTabularPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mregistered\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mag_registered/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresets\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m predictions_registered = predictor_registered.predict(\u001b[33m\"\u001b[39m\u001b[33mtest.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Train a predictor for \"casual\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogluon\\common\\utils\\decorators.py:34\u001b[39m, in \u001b[36munpack.<locals>._unpack_inner.<locals>._call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(*args, **kwargs):\n\u001b[32m     33\u001b[39m     gargs, gkwargs = g(*other_args, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1393\u001b[39m, in \u001b[36mTabularPredictor.fit\u001b[39m\u001b[34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dynamic_stacking:\n\u001b[32m   1388\u001b[39m     logger.log(\n\u001b[32m   1389\u001b[39m         \u001b[32m20\u001b[39m,\n\u001b[32m   1390\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDyStack is enabled (dynamic_stacking=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdynamic_stacking\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1391\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1392\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1393\u001b[39m     num_stack_levels, time_limit = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dynamic_stacking\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mds_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m     logger.info(\n\u001b[32m   1395\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting main fit with num_stack_levels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_stack_levels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1396\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mFor future fit calls on this dataset, you can skip DyStack to save time: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1397\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`predictor.fit(..., dynamic_stacking=False, num_stack_levels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_stack_levels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1398\u001b[39m     )\n\u001b[32m   1400\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (time_limit <= \u001b[32m0\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1493\u001b[39m, in \u001b[36mTabularPredictor._dynamic_stacking\u001b[39m\u001b[34m(self, ag_fit_kwargs, ag_post_fit_kwargs, validation_procedure, detection_time_frac, holdout_frac, n_folds, n_repeats, memory_safe_fits, clean_up_fits, enable_ray_logging, enable_callbacks, holdout_data)\u001b[39m\n\u001b[32m   1490\u001b[39m         _, holdout_data, _, _ = \u001b[38;5;28mself\u001b[39m._validate_fit_data(train_data=X, tuning_data=holdout_data)\n\u001b[32m   1491\u001b[39m         ds_fit_kwargs[\u001b[33m\"\u001b[39m\u001b[33mds_fit_context\u001b[39m\u001b[33m\"\u001b[39m] = os.path.join(ds_fit_context, \u001b[33m\"\u001b[39m\u001b[33msub_fit_custom_ho\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m     stacked_overfitting = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sub_fit_memory_save_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_ag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_ag_post_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1503\u001b[39m     \u001b[38;5;66;03m# Holdout is false, use (repeated) cross-validation\u001b[39;00m\n\u001b[32m   1504\u001b[39m     is_stratified = \u001b[38;5;28mself\u001b[39m.problem_type \u001b[38;5;129;01min\u001b[39;00m [BINARY, MULTICLASS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1713\u001b[39m, in \u001b[36mTabularPredictor._sub_fit_memory_save_wrapper\u001b[39m\u001b[34m(self, train_data, time_limit, time_start, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[39m\n\u001b[32m   1710\u001b[39m     normal_fit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1712\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normal_fit:\n\u001b[32m-> \u001b[39m\u001b[32m1713\u001b[39m     stacked_overfitting, ho_leaderboard, exception = \u001b[43m_dystack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1714\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1719\u001b[39m \u001b[43m        \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1720\u001b[39m \u001b[43m        \u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1724\u001b[39m     logger.log(\u001b[32m40\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWarning: Exception encountered during DyStack sub-fit:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:5909\u001b[39m, in \u001b[36m_dystack\u001b[39m\u001b[34m(predictor, train_data, time_limit, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[39m\n\u001b[32m   5907\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m clean_up_fits:\n\u001b[32m   5908\u001b[39m     logger.log(\u001b[32m20\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDeleting DyStack predictor artifacts (clean_up_fits=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_up_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m5909\u001b[39m     \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_fit_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5910\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5911\u001b[39m     predictor._sub_fits.append(ds_fit_context)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\shutil.py:790\u001b[39m, in \u001b[36mrmtree\u001b[39m\u001b[34m(path, ignore_errors, onerror, onexc, dir_fd)\u001b[39m\n\u001b[32m    788\u001b[39m     \u001b[38;5;66;03m# can't continue even if onexc hook returns\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monexc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\shutil.py:629\u001b[39m, in \u001b[36m_rmtree_unsafe\u001b[39m\u001b[34m(path, onexc)\u001b[39m\n\u001b[32m    627\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    628\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m             \u001b[43monexc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    631\u001b[39m     os.rmdir(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\shutil.py:625\u001b[39m, in \u001b[36m_rmtree_unsafe\u001b[39m\u001b[34m(path, onexc)\u001b[39m\n\u001b[32m    623\u001b[39m fullname = os.path.join(dirpath, name)\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'c:\\\\Users\\\\charl\\\\Desktop\\\\code\\\\ag_registered\\\\ds_sub_fit\\\\sub_fit_ho\\\\models\\\\LightGBMLarge_BAG_L1\\\\S1F3\\\\model.pkl'"
     ]
    }
   ],
   "source": [
    "%pip install autogluon.tabular\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import gc\n",
    "\n",
    "# Train a predictor for \"registered\"\n",
    "predictor_registered = TabularPredictor(label=\"registered\", path=\"ag_registered/\").fit(\"train.csv\", presets=\"best\")\n",
    "predictions_registered = predictor_registered.predict(\"test.csv\")\n",
    "\n",
    "# Explicitly delete and collect garbage to release file handles\n",
    "del predictor_registered\n",
    "gc.collect()\n",
    "\n",
    "# Train a predictor for \"casual\"\n",
    "predictor_casual = TabularPredictor(label=\"casual\", path=\"ag_casual/\").fit(\"train.csv\", presets=\"best\")\n",
    "predictions_casual = predictor_casual.predict(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb143448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f30e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
